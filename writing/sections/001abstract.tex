
Balancing multiple competing and conflicting objectives is an essential task for any artificial intelligence tasked with satisfying human values or preferences. Conflict arises both from misalignment between individuals with competing values, but also between conflicting value systems held by a single human. Based on principles of loss-aversion and maximin, we designed a set of soft maximin approaches to multi-objective decison-making. We tested these on previously-tested environments, and found that one new approach in particular, `split-function exp-log loss aversion', performs better than the thresholded alignment objective method, the state of the art described in \cite{vamplew_potential-based_2021}. We explore approaches to further improve multi-objective decision-making using soft maximin approaches.

`cover a middle ground between the linear approach and a lexicographic approach'