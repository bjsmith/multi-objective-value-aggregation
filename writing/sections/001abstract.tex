
Balancing multiple competing and conflicting objectives is an essential task for any artificial intelligence tasked with satisfying human values or preferences. Conflict arises both from misalignment between individuals with competing values, but also between conflicting value systems held by a single human. Starting with principles of loss-aversion and maximin, we designed a set of soft maximin function approaches to multi-objective decision-making. Bench-marking these functions in a set of previously-developed environments, we found that one new approach in particular, `split-function exp-log loss aversion', learns faster than the thresholded alignment objective method, the state of the art described in \cite{vamplew_potential-based_2021}, on the `BreakableBottles' task. We explore approaches to further improve multi-objective decision-making using soft maximin approaches.

%`cover a middle ground between the linear approach and a lexicographic approach - This is now explained in section 1.4 "Our proposed functions are in turn a compromise between a thresholded leximin and the linear MEU function - they are continuous functions, while still representing the loss aversion aspect as a kind of soft maximin approach."

%additional text